{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uZw05y6ON7X7",
    "ExecuteTime": {
     "end_time": "2024-01-08T08:31:41.231526200Z",
     "start_time": "2024-01-08T08:31:35.561571Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('./data/Data Set for Chapter - Sheet1.csv')\n",
    "df = df.drop('S.no',axis = 1)\n",
    "df = df.dropna()\n",
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "kkiUgBSOPfTv",
    "outputId": "44f56e54-716e-4ee6-81f9-35355452211d",
    "ExecuteTime": {
     "end_time": "2024-01-08T08:32:15.823786700Z",
     "start_time": "2024-01-08T08:32:15.768769400Z"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "      Age  Intimate Partners  \\\n0    45.0                  4   \n1    43.0                  4   \n2    39.0                  5   \n3    35.0                  5   \n4    32.0                  1   \n..    ...                ...   \n540  36.0                  2   \n541  45.0                  4   \n542  43.0                  4   \n543  39.0                  5   \n544  35.0                  5   \n\n     Protection Usage (0: Never, 1: Sometimes, 2: Always)  Symptoms  Location  \\\n0                                                    0            0         2   \n1                                                    0            0         2   \n2                                                    0            0         3   \n3                                                    2            0         3   \n4                                                    1            1         2   \n..                                                 ...          ...       ...   \n540                                                  0            1         2   \n541                                                  0            0         2   \n542                                                  0            0         3   \n543                                                  0            0         3   \n544                                                  2            0         1   \n\n     Education  STD Testing history (0: No, 1: Yes)  STD Status  \n0            1                                    1           1  \n1            1                                    1           1  \n2            1                                    1           1  \n3            1                                    0           1  \n4            1                                    0           0  \n..         ...                                  ...         ...  \n540          0                                    1           1  \n541          0                                    1           1  \n542          0                                    0           0  \n543          0                                    0           0  \n544          0                                    1           1  \n\n[544 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Intimate Partners</th>\n      <th>Protection Usage (0: Never, 1: Sometimes, 2: Always)</th>\n      <th>Symptoms</th>\n      <th>Location</th>\n      <th>Education</th>\n      <th>STD Testing history (0: No, 1: Yes)</th>\n      <th>STD Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>45.0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>43.0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>39.0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35.0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>540</th>\n      <td>36.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>541</th>\n      <td>45.0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>542</th>\n      <td>43.0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>543</th>\n      <td>39.0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>544</th>\n      <td>35.0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>544 rows Ã— 8 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_df,test_df = train_test_split(df,test_size=0.2,random_state=42)"
   ],
   "metadata": {
    "id": "tdv0NgVnQDtV",
    "ExecuteTime": {
     "end_time": "2024-01-08T08:32:19.813828600Z",
     "start_time": "2024-01-08T08:32:19.799838900Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "## Training Autoencoder Model\n",
    "\n",
    "X = df.drop('STD Status',axis = 1)\n",
    "y = df['STD Status']\n",
    "\n",
    "X_scaled = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "X_infected = X_scaled[y==1]\n",
    "X_uninfected = X_scaled[y==0]\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Autoencoder,self).__init__()\n",
    "    self.encoder = nn.Sequential(\n",
    "        nn.Linear(7,5),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(5,3),\n",
    "    )\n",
    "    self.decoder = nn.Sequential(\n",
    "        nn.Linear(3,5),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(5,7),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "  def forward(self,x):\n",
    "    x = self.encoder(x)\n",
    "    x = self.decoder(x)\n",
    "    return x\n",
    "\n",
    "autoencoder = Autoencoder()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adadelta(autoencoder.parameters())\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 30\n",
    "\n",
    "X_infected_tensor = torch.FloatTensor(X_infected)\n",
    "X_uninfected_tensor = torch.FloatTensor(X_uninfected)\n",
    "\n",
    "infected_dataset = TensorDataset(X_infected_tensor,X_infected_tensor)\n",
    "uninfected_dataset = TensorDataset(X_uninfected_tensor,X_uninfected_tensor)\n",
    "\n",
    "dataset = ConcatDataset([infected_dataset,uninfected_dataset])\n",
    "loader = DataLoader(dataset,batch_size=batch_size,shuffle=True)\n",
    "infected_loader = DataLoader(infected_dataset,batch_size=batch_size,shuffle=True)\n",
    "uninfected_loader = DataLoader(uninfected_dataset,batch_size=batch_size,shuffle=True)\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  for data in loader:\n",
    "    inputs,targets = data\n",
    "    optimizer.zero_grad()\n",
    "    outputs = autoencoder(inputs)\n",
    "    loss = criterion(outputs,targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.detach().numpy())\n",
    "\n",
    "\n",
    "#losses[-100:]"
   ],
   "metadata": {
    "id": "tSsXVlogQaQx",
    "ExecuteTime": {
     "end_time": "2024-01-08T08:35:02.888058Z",
     "start_time": "2024-01-08T08:35:01.057574800Z"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def encoded(model,data_loader):\n",
    "  hidden_rep = []\n",
    "  with torch.no_grad():\n",
    "    for data in data_loader:\n",
    "      inputs,_=data\n",
    "      hidden = model.encoder(inputs)\n",
    "      hidden_rep.append(hidden)\n",
    "  return torch.cat(hidden_rep,dim=0)\n",
    "\n",
    "infected_encoded = encoded(autoencoder,infected_loader)\n",
    "uninfected_encoded = encoded(autoencoder,uninfected_loader)\n",
    "\n",
    "encoded_X = torch.cat([infected_encoded,uninfected_encoded],dim=0).numpy()\n",
    "y_infected = np.ones(infected_encoded.shape[0])\n",
    "y_uninfected = np.zeros(uninfected_encoded.shape[0])\n",
    "encoded_y = np.append(y_infected,y_uninfected)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(encoded_X,encoded_y,test_size=0.2)"
   ],
   "metadata": {
    "id": "ZDg2UTNJQy6u",
    "ExecuteTime": {
     "end_time": "2024-01-08T08:35:20.461456100Z",
     "start_time": "2024-01-08T08:35:20.428232300Z"
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "gmm = GaussianMixture(n_components=2,random_state=42)\n",
    "gmm.fit(X_train)\n",
    "y_pred=gmm.predict(X_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "report = classification_report(y_test,y_pred)"
   ],
   "metadata": {
    "id": "qI7gO0beYJ4R",
    "ExecuteTime": {
     "end_time": "2024-01-08T08:35:21.503519800Z",
     "start_time": "2024-01-08T08:35:21.458529400Z"
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(report)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNsVnNXEQ0M7",
    "outputId": "bb4bb0b4-74a6-4af9-f890-d2cc0a378c03",
    "ExecuteTime": {
     "end_time": "2024-01-08T08:35:22.047210100Z",
     "start_time": "2024-01-08T08:35:22.034670400Z"
    }
   },
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        54\n",
      "         1.0       0.14      0.16      0.15        55\n",
      "\n",
      "    accuracy                           0.08       109\n",
      "   macro avg       0.07      0.08      0.08       109\n",
      "weighted avg       0.07      0.08      0.08       109\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_pca, y_train)\n",
    "y_pred_pca = knn.predict(X_test_pca)\n",
    "\n",
    "\n",
    "conf_matrix_pca = confusion_matrix(y_test, y_pred_pca)\n",
    "report_pca = classification_report(y_test, y_pred_pca)\n",
    "\n",
    "print(\"Confusion Matrix (PCA):\")\n",
    "print(conf_matrix_pca)\n",
    "\n",
    "print(\"\\nClassification Report (PCA):\")\n",
    "print(report_pca)\n"
   ],
   "metadata": {
    "id": "kcvquQTuV0ZX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "95e62a5f-c785-4409-e953-f489b20ac68d"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix (PCA):\n",
      "[[56  1]\n",
      " [ 7 45]]\n",
      "\n",
      "Classification Report (PCA):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.98      0.93        57\n",
      "         1.0       0.98      0.87      0.92        52\n",
      "\n",
      "    accuracy                           0.93       109\n",
      "   macro avg       0.93      0.92      0.93       109\n",
      "weighted avg       0.93      0.93      0.93       109\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(autoencoder.state_dict(), 'Autoencoder.pth')"
   ],
   "metadata": {
    "id": "rplHOl3D_zYY"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "## LOADING WEIGHTS ##\n",
    "model = Autoencoder()\n",
    "model.load_state_dict(torch.load('Autoencoder.pth'))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VVKNSqxWAnw6",
    "outputId": "ba08bb26-cd08-4e99-fcee-07c338a31d79",
    "ExecuteTime": {
     "end_time": "2024-01-08T08:32:58.499057600Z",
     "start_time": "2024-01-08T08:32:58.460540Z"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implementing XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#implementing xgboost\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_X,encoded_y,test_size=0.3,random_state=41) # 70% training and 30% test\n",
    "X_cv,y_cv = X_test[:int(len(X_test)/2)],y_test[:int(len(y_test)/2)]\n",
    "X_test,y_test = X_test[int(len(X_test)/2):],y_test[int(len(y_test)/2):]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eta=0.1,\n",
    "    max_depth=5,\n",
    "    min_child_weight=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.9\n",
    ")\n",
    "\n",
    "# Create classification matrices\n",
    "dtrain_clf = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
    "dtest_clf = xgb.DMatrix(X_test, y_test, enable_categorical=True)\n",
    "param_grid = { 'eta': [0.01, 0.1, 0.2,0.5],\n",
    "               'max_depth': [3, 5, 7, 9, 11, 15, 20],\n",
    "               'min_child_weight': [1,3,5,7,10],\n",
    "               'subsample': [0.7,0.8, 0.9],\n",
    "               'colsample_bytree': [0.7,0.8, 0.9]\n",
    "             }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "random_search_xgboost_model = RandomizedSearchCV(\n",
    "    xgb_clf, param_grid, cv=5, scoring='neg_log_loss', n_iter=100, verbose=1\n",
    ")\n",
    "# Fit the model on the training data\n",
    "random_search_xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Display the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", random_search_xgboost_model.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_random_search_xgb_model = random_search_xgboost_model.best_estimator_\n",
    "\n",
    "# Evaluate the model with additional metrics\n",
    "random_predictions = best_random_search_xgb_model.predict(X_cv)\n",
    "print(\"Accuracy:\", accuracy_score(y_cv, random_predictions))\n",
    "print(\"Precision:\", precision_score(y_cv, random_predictions))\n",
    "print(\"Recall:\", recall_score(y_cv, random_predictions))\n",
    "report = classification_report(y_cv,random_predictions)\n",
    "print(report)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_params = random_search_xgboost_model.best_params_\n",
    "\n",
    "# Re-run XGBoost CV with early stopping and additional metrics\n",
    "xgb_random_search_tuned_results = xgb.cv(\n",
    "    best_params, dtrain_clf,\n",
    "    num_boost_round=1000,\n",
    "    nfold=3,\n",
    "    early_stopping_rounds=10,\n",
    "    metrics=[\"auc\", \"error\", \"logloss\"],\n",
    "    verbose_eval=True\n",
    ")\n",
    "\n",
    "# Display tuned results\n",
    "print(\"Tuned Results:\")\n",
    "print(xgb_random_search_tuned_results.iloc[-1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the grid search object\n",
    "grid_search_xgboost_model = GridSearchCV(\n",
    "    xgb_clf, param_grid, cv=5, scoring='neg_log_loss', verbose=5\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "grid_search_xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Display the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search_xgboost_model.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_grid_search_xgb_model = grid_search_xgboost_model.best_estimator_\n",
    "\n",
    "# Evaluate the model with additional metrics\n",
    "grid_predictions = best_grid_search_xgb_model.predict(X_cv)\n",
    "print(\"Accuracy:\", accuracy_score(y_cv, grid_predictions))\n",
    "print(\"Precision:\", precision_score(y_cv, grid_predictions))\n",
    "print(\"Recall:\", recall_score(y_cv, grid_predictions))\n",
    "report = classification_report(y_cv,grid_predictions)\n",
    "print(report)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the best parameters from  grid search\n",
    "best_params = grid_search_xgboost_model.best_params_\n",
    "\n",
    "# Re-run XGBoost CV with early stopping and additional metrics\n",
    "xgb_grid_search_tuned_results = xgb.cv(\n",
    "    best_params, dtrain_clf,\n",
    "    num_boost_round=1000,\n",
    "    nfold=5,\n",
    "    early_stopping_rounds=10,\n",
    "    metrics=[\"logloss\", \"auc\", \"error\"],\n",
    "    verbose_eval=True\n",
    ")\n",
    "\n",
    "# Display tuned results\n",
    "print(\"Tuned Results:\")\n",
    "print(xgb_grid_search_tuned_results.iloc[-1])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
